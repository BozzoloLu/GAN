{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 15:46:47.730153: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-30 15:46:47.730192: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pennylane as qml\n",
    "from pennylane.templates import RandomLayers\n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Sequential, Linear, LeakyReLU, Sigmoid\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------- Classical Linear Generator -------------------------------#\n",
    "\n",
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.dense_layer = nn.Linear(self.z_dim, 32)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.lin = nn.Linear(32, 64)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.activation(self.lin(self.relu(self.dense_layer(x))))\n",
    "\n",
    "\n",
    "#------------------------------- Quantum Generator -------------------------------#\n",
    "\n",
    "\n",
    "#------------- Making quantum circuit -------------#\n",
    "n_qubits = 5\n",
    "\n",
    "@qml.qnode(qml.device(\"lightning.qubit\", wires=n_qubits), interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "def quantum_generator_circuit(noise, gen_weights, gen_n_layers, n_qubits):\n",
    "\n",
    "    gen_weights = gen_weights.reshape(gen_n_layers, n_qubits)\n",
    "\n",
    "    # Encoding layer\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(noise[i], wires=i)\n",
    "\n",
    "    # PQC layers\n",
    "    for i in range(gen_n_layers):\n",
    "\n",
    "        # Rotation gates\n",
    "        for y in range(n_qubits):\n",
    "            qml.RY(gen_weights[i][y], wires=y)   \n",
    "            \n",
    "        # Entangling gates\n",
    "        for y in range(n_qubits - 1):\n",
    "            qml.CZ(wires=[y, y + 1])\n",
    "\n",
    "    # Returning probability of each computational basis state\n",
    "    return qml.probs(wires=list(range(n_qubits)))\n",
    "\n",
    "\n",
    "\n",
    "#------------- Patchuing images with quantum circuit -------------#\n",
    "\n",
    "class QuantumGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, n_qubits, ancillary_qubits, gen_n_layers, n_generators, device, q_delta=1):\n",
    "        super(QuantumGenerator, self).__init__()\n",
    "\n",
    "        self.n_qubits = n_qubits\n",
    "        self.ancillary_qubits = ancillary_qubits\n",
    "        self.gen_n_layers = gen_n_layers\n",
    "        self.n_generators = n_generators\n",
    "        self.device = device\n",
    "        self.vqc_params = nn.ParameterList([nn.Parameter(q_delta * torch.rand(self.gen_n_layers * self.n_qubits), \n",
    "                                            requires_grad=True)for _ in range(self.n_generators)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        patch_size = 2 ** (self.n_qubits - self.ancillary_qubits)\n",
    "\n",
    "        images = torch.Tensor(x.size(0), 0).to(self.device)\n",
    "\n",
    "        # Iterate over all sub-generators\n",
    "        for params in self.vqc_params:\n",
    "            \n",
    "            patches = torch.Tensor(0, patch_size).to(self.device)\n",
    "            for elem in x:\n",
    "                \n",
    "                probs = quantum_generator_circuit(elem, params, self.gen_n_layers, self.n_qubits)\n",
    "                partial_measure = probs[: (2 ** (n_qubits - self.ancillary_qubits))]\n",
    "                partial_measure /= torch.sum(probs)\n",
    "            \n",
    "                out = partial_measure / torch.max(partial_measure)\n",
    "                out = out.float().unsqueeze(0)\n",
    "                patches = torch.cat((patches, out))\n",
    "\n",
    "            # Building the image\n",
    "            images = torch.cat((images, patches), 1)\n",
    "\n",
    "        return images\n",
    "\n",
    "\n",
    "#------------------------------- Classical Linear Discriminator -------------------------------#\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, image_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.linear1 = nn.Linear(self.image_size * self.image_size, 64)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.linear2 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sigmoid(self.linear2(self.relu1(self.linear1(x))))\n",
    "\n",
    "# class Discriminator(nn.Module):\n",
    "#     \"\"\"Fully connected classical discriminator\"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             # Inputs to first hidden layer (num_input_features -> 64)\n",
    "#             nn.Linear(8*8, 64),\n",
    "#             nn.ReLU(),\n",
    "#             # First hidden layer (64 -> 16)\n",
    "#             nn.Linear(64, 16),\n",
    "#             nn.ReLU(),\n",
    "#             # Second hidden layer (16 -> output)\n",
    "#             nn.Linear(16, 1),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_data(x, y, label, image_size):\n",
    "\n",
    "    arr = []\n",
    "    arr_input = []\n",
    "\n",
    "    for t, l in zip(x, y):\n",
    "        if l in label:\n",
    "            t = torch.tensor(t, dtype = torch.float32).reshape(image_size, image_size)\n",
    "            t = t/16\n",
    "            arr.append((t, l))\n",
    "            arr_input.append(t)\n",
    "    return arr, arr_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, model_type, dataloader, gen_net, disc_net, noise_dim, image_size, batch_size, loss, lr_gen, lr_disc, device, save_path):\n",
    "\n",
    "        \"For 0 and 1 features ---> opt = torch.Adam, random = torch.randn, epochs = 1000, lr_disc = lr_gen = 0.0001\"\n",
    "\n",
    "        self.model_type = model_type\n",
    "        self.dataloader = dataloader\n",
    "        self.gen_net = gen_net\n",
    "        self.disc_net = disc_net\n",
    "        self.noise_dim = noise_dim \n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.lr_gen = lr_gen\n",
    "        self.lr_disc = lr_disc\n",
    "        self.loss = loss\n",
    "        self.device = device\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.gen_opt = optim.SGD(self.gen_net.parameters(), lr=self.lr_gen)\n",
    "        self.disc_opt = optim.SGD(self.disc_net.parameters(), lr=self.lr_disc)        \n",
    "\n",
    "        self.real_labels = torch.full((self.batch_size,), 1.0, dtype=torch.float, device=self.device)\n",
    "        self.fake_labels = torch.full((self.batch_size,), 0.0, dtype=torch.float, device=self.device)\n",
    "\n",
    "        self.loss_g = []\n",
    "        self.loss_d = []\n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "\n",
    "        # Data for training the discriminator\n",
    "        data = data.reshape(-1, self.image_size * self.image_size)\n",
    "        real_data = data.to(self.device)\n",
    "\n",
    "        # Generating noise\n",
    "        noise = torch.rand(self.batch_size, self.noise_dim, device=self.device) * np.pi / 2\n",
    "        fake_data = self.gen_net(noise)\n",
    "\n",
    "        #---------------- Discriminator training ----------------# \n",
    "        self.disc_opt.zero_grad()\n",
    "        disc_out_real = self.disc_net(real_data).view(-1)\n",
    "        disc_out_fake = self.disc_net(fake_data.detach()).view(-1)\n",
    "\n",
    "        disc_error_real = self.loss(disc_out_real, self.real_labels)\n",
    "        disc_error_fake = self.loss(disc_out_fake, self.fake_labels)\n",
    "        \n",
    "        disc_error_real.backward()\n",
    "        disc_error_fake.backward()\n",
    "\n",
    "        disc_error = disc_error_real + disc_error_fake\n",
    "        self.disc_opt.step()\n",
    "\n",
    "        #---------------- Generator training ----------------#\n",
    "        self.gen_opt.zero_grad()\n",
    "        # Generating fake images\n",
    "        noise = torch.rand(self.batch_size, self.noise_dim)\n",
    "        fake_data = self.gen_net(noise)\n",
    "        disc_out_fake = self.disc_net(fake_data).view(-1)\n",
    "        gen_error = self.loss(disc_out_fake, self.real_labels)\n",
    "        gen_error.backward()\n",
    "        self.gen_opt.step()        \n",
    "\n",
    "        self.loss_g.append(gen_error.item())\n",
    "        self.loss_d.append(disc_error.item())\n",
    "\n",
    "        return gen_error, disc_error\n",
    "\n",
    "\n",
    "    def learn(self, epochs):\n",
    "\n",
    "        # Fixed noise to visually track the generated images throughout training\n",
    "        fixed_noise = torch.rand(8, self.noise_dim, device=self.device) * np.pi / 2\n",
    "\n",
    "        self.results = []        \n",
    "        self.ep_d_loss = []\n",
    "        self.ep_g_loss = []    \n",
    "                      \n",
    "        \n",
    "        with tqdm(range(epochs)) as tepochs:#total=len(self.dataloader), ncols=140, desc=f'epoch {epoch}') as bar:\n",
    "\n",
    "            for epoch in tepochs:\n",
    "\n",
    "                self.loss_g = []\n",
    "                self.loss_d = []     \n",
    "        \n",
    "                for data, _ in self.dataloader:\n",
    "\n",
    "                    lg, ld = self.train_step(data)\n",
    "\n",
    "                    self.loss_g.append(lg.item())\n",
    "                    self.loss_d.append(ld.item())                    \n",
    "\n",
    "                test_images = self.gen_net(fixed_noise).view(8,1,self.image_size,self.image_size).cpu().detach()\n",
    "\n",
    "                \n",
    "                \n",
    "                # Collecting and saving results\n",
    "                self.results.append(test_images)\n",
    "                torch.save(self.results, self.save_path + 'synthetic.pt')  \n",
    "\n",
    "                # Collecting and saving losses\n",
    "                self.ep_g_loss.append(np.mean(self.loss_g))\n",
    "                self.ep_d_loss.append(np.mean(self.loss_d))\n",
    "                torch.save(self.ep_g_loss, self.save_path + 'gen_loss.pt') \n",
    "                torch.save(self.ep_d_loss, self.save_path + 'disc_loss.pt')  \n",
    "\n",
    "                \n",
    "                tepochs.set_postfix({'Generator loss' : np.mean(self.loss_g), 'Discriminator loss': np.mean(self.loss_d)})\n",
    "\n",
    "            # Saving generator model\n",
    "            if self.model_type == 'Classical_linear':\n",
    "                torch.save(self.gen_net, self.save_path + f'lin_gen_epoch_{epoch}')\n",
    "            elif self.model_type == 'Quantum_linear':\n",
    "                torch.save(self.gen_net, self.save_path + f'lin_q_gen_epoch_{epoch}')\n",
    "            else:\n",
    "                print('Typology not admitted.')\n",
    "\n",
    "            # if epoch == epochs:\n",
    "            #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# save_path = 'torch_results/GAN/GAN_linear/' + current_time + '/'\n",
    "# #qsave_path = 'torch_results/QGAN/QGAN_linear/' + current_time + '/'\n",
    "# summary_writer = tf.summary.create_file_writer(save_path)\n",
    "\n",
    "# noise_dim = 5\n",
    "# image_size = 8\n",
    "# batch_size = 1\n",
    "# loss = nn.BCELoss()\n",
    "# lr_gen = 0.3#0.03# 0.001\n",
    "# lr_disc = 0.01#0.001\n",
    "# epochs = 3\n",
    "# n_qubits = 5 \n",
    "# ancillary_qubits = 1  \n",
    "# gen_n_layers = 6  \n",
    "# n_generators = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator = Discriminator(image_size).to(device)\n",
    "# qgenerator = QuantumGenerator(n_qubits, ancillary_qubits, gen_n_layers, n_generators, device).to(device)\n",
    "# generator = Generator(noise_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gan = GAN(network_type = 'Classical_linear', dataloader = dataloader, gen_net = generator, disc_net = discriminator, noise_dim = noise_dim, image_size = image_size, batch_size = batch_size, loss = loss,\n",
    "#           lr_gen = lr_gen, lr_disc = lr_disc, device = device, save_path = save_path)\n",
    "\n",
    "# gan.learn(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(labels, generator, discriminator, noise_dim, image_size, batch_size, loss, lr_gen, lr_disc, device, epochs, runs, model_type, reset_parameters=True):\n",
    "\n",
    "    digits, targets = datasets.load_digits(return_X_y=True)\n",
    "    rd, inp = resize_data(digits, targets, label = labels, image_size = image_size)\n",
    "    dataloader = torch.utils.data.DataLoader(rd, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    for run in range(runs):\n",
    "\n",
    "        print(f'RUN {run+1}')\n",
    "        \n",
    "        for i in labels:\n",
    "\n",
    "            print(f'Label {i}:')\n",
    "\n",
    "            current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "            if model_type == 'Classical_linear':\n",
    "                \n",
    "                save_path = 'torch_results/GAN/GAN_linear/' + current_time + '/'\n",
    "\n",
    "            else:\n",
    "\n",
    "                save_path = 'torch_results/QGAN/QGAN_linear/' + current_time + '/'\n",
    "            summary_writer = tf.summary.create_file_writer(save_path)\n",
    "\n",
    "            gan = GAN(model_type = model_type, dataloader = dataloader, gen_net = generator, disc_net = discriminator, noise_dim = noise_dim, image_size = image_size, \n",
    "                      batch_size = batch_size, loss = loss, lr_gen = lr_gen, lr_disc = lr_disc, device = device, save_path = save_path)\n",
    "\n",
    "            gan.learn(epochs)\n",
    "\n",
    "            if reset_parameters:\n",
    "\n",
    "                for layer in gan.gen_net.children():\n",
    "                    if hasattr(layer, 'reset_parameters'):\n",
    "                        layer.reset_parameters()\n",
    "\n",
    "                for layer in gan.disc_net.children():\n",
    "                    if hasattr(layer, 'reset_parameters'):\n",
    "                        layer.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-30 15:46:50.231469: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-30 15:46:50.231506: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-30 15:46:50.231521: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vt-bozzololu): /proc/driver/nvidia/version does not exist\n",
      "2023-01-30 15:46:50.231787: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUN 1\n",
      "Label 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:09<00:00, 183.11s/it, Generator loss=1.62, Discriminator loss=0.412] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [10:02<00:00, 200.77s/it, Generator loss=1.49, Discriminator loss=0.427] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [09:13<00:00, 184.62s/it, Generator loss=1.43, Discriminator loss=0.427] \n"
     ]
    }
   ],
   "source": [
    "labels = [0,1,2]\n",
    "runs = 1\n",
    "epochs = 3\n",
    "batch_size = 1\n",
    "noise_dim = 5\n",
    "image_size = 8\n",
    "loss = nn.BCELoss()\n",
    "lr_gen = 0.3#0.03# 0.001\n",
    "lr_disc = 0.01#0.001\n",
    "n_qubits = 5 \n",
    "ancillary_qubits = 1  \n",
    "gen_n_layers = 6  \n",
    "n_generators = 4 \n",
    "model_type = ['Classical_linear', 'Quantum_linear']\n",
    "\n",
    "\n",
    "discriminator = Discriminator(image_size).to(device)\n",
    "qgenerator = QuantumGenerator(n_qubits, ancillary_qubits, gen_n_layers, n_generators, device).to(device)\n",
    "generator = Generator(noise_dim).to(device)\n",
    "\n",
    "results = run_model(labels, qgenerator, discriminator, noise_dim, image_size, batch_size, loss, lr_gen, lr_disc, device, epochs, runs, model_type[1])\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure()\n",
    "# f, axarr = plt.subplots(8, 8) \n",
    "# for i, ax in enumerate(axarr.ravel()):\n",
    "#     ax.imshow(generator(torch.rand(1,noise_dim)).detach().numpy().reshape(8,8), cmap = 'gray')\n",
    "#     ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "# f.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# outer = gridspec.GridSpec(len(gan.results), 2, wspace=0.1)\n",
    "\n",
    "# for i, images in enumerate(gan.results):\n",
    "#     inner = gridspec.GridSpecFromSubplotSpec(1, images.size(0), subplot_spec=outer[i])\n",
    "    \n",
    "#     images = torch.squeeze(images, dim=1)\n",
    "#     for j, im in enumerate(images):\n",
    "\n",
    "#         ax = plt.Subplot(fig, inner[j])\n",
    "#         ax.imshow(im.numpy(), cmap=\"gray\")\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#         if j==0:\n",
    "#             ax.set_title(f'Epoch {i}', loc='left')\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = np.arange(len(gan.loss_d))\n",
    "# plt.plot(x, gan.loss_d, label = \"Discriminator loss\")\n",
    "# plt.plot(x, gan.loss_g, label = \"Generator loss\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41b44beeb6ae1f78ee853589a4fc9a204ef8b2c5ec7d95e779faecfadf9e001f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
