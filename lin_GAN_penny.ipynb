{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:52:18.023315: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-26 10:52:18.023355: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pennylane as qml\n",
    "from pennylane.templates import RandomLayers\n",
    "from sklearn import datasets\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import Sequential, Linear, LeakyReLU, Sigmoid\n",
    "from torch.optim import Adam\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models\n",
    "from torchsummary import summary\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choosing the device\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# # Setting the random seed \n",
    "# seed = 43\n",
    "# torch.manual_seed(seed)\n",
    "# np.random.seed(seed)\n",
    "# random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_data(x, y, label, image_size):\n",
    "\n",
    "    arr = []\n",
    "    arr_input = []\n",
    "\n",
    "    for t, l in zip(x, y):\n",
    "        if l in label:\n",
    "            t = torch.tensor(t, dtype = torch.float32).reshape(image_size, image_size)\n",
    "            t = t/16\n",
    "            arr.append((t, l))\n",
    "            arr_input.append(t)\n",
    "    return arr, arr_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_dim = 5\n",
    "image_size = 8\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset and create a batch\n",
    "digits, targets = datasets.load_digits(return_X_y=True)\n",
    "# digits /= 16\n",
    "# dataloader = DataLoader(list(zip(digits.astype(\"float32\"), targets.astype(\"float32\"))), \n",
    "#                         batch_size= batch_size, shuffle= True, drop_last= True)\n",
    "\n",
    "rd, inp = resize_data(digits, targets, label = (3,), image_size = image_size)\n",
    "dataloader = torch.utils.data.DataLoader(rd, batch_size=batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #show the first iteration batch\n",
    "# images, labels = next(iter(dataloader))\n",
    "# plt.figure()\n",
    "# f, axarr = plt.subplots(8,8, figsize=(10,10)) \n",
    "# for i, ax in enumerate(axarr.ravel()):\n",
    "#     ax.imshow(images[i].reshape(8,8), cmap = 'gray')\n",
    "#     ax.tick_params(left=False,\n",
    "#                 bottom=False,\n",
    "#                 labelleft=False,\n",
    "#                 labelbottom=False)\n",
    "#     ax.set_title(f\"Num:{labels[i]}\")\n",
    "# f.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim\n",
    "        self.dense_layer = nn.Linear(self.z_dim, 2)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.lin = nn.Linear(2, 64)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dense_layer(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.lin(x)\n",
    "        x = self.activation(x)\n",
    "        return x#self.activation(self.dense_layer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 1, 2]              12\n",
      "         LeakyReLU-2                 [-1, 1, 2]               0\n",
      "            Linear-3                [-1, 1, 64]             192\n",
      "           Sigmoid-4                [-1, 1, 64]               0\n",
      "================================================================\n",
      "Total params: 204\n",
      "Trainable params: 204\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "generator = Generator(noise_dim).to(device)\n",
    "summary(generator, (1, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_qubits = 5\n",
    "\n",
    "@qml.qnode(qml.device(\"default.qubit\", wires=n_qubits), interface=\"torch\", diff_method=\"parameter-shift\")\n",
    "def quantum_generator_circuit(noise, gen_weights, gen_n_layers, n_qubits):\n",
    "\n",
    "    gen_weights = gen_weights.reshape(gen_n_layers, n_qubits)\n",
    "\n",
    "    # Encoding layer\n",
    "    for i in range(n_qubits):\n",
    "        qml.RY(noise[i], wires=i)\n",
    "\n",
    "    #qml.AngleEmbedding(noise, wires=range(n_qubits))\n",
    "\n",
    "    # PQC layers\n",
    "    for i in range(gen_n_layers):\n",
    "\n",
    "        # Rotation gates\n",
    "        for y in range(n_qubits):\n",
    "            #for w in range(n_gate_per_layer):\n",
    "            #qml.RX(gen_weights[i][y], wires=y)  \n",
    "            qml.RY(gen_weights[i][y], wires=y)   \n",
    "            #qml.RZ(gen_weights[i][y], wires=y) \n",
    "\n",
    "    #RandomLayers(gen_weights, wires = list(range(n_qubits)), ratio_imprim = 0.1)\n",
    "            \n",
    "        # Entangling gates\n",
    "        for y in range(n_qubits - 1):\n",
    "            qml.CZ(wires=[y, y + 1])\n",
    "\n",
    "    # Returning probability of each computational basis state\n",
    "    return qml.probs(wires=list(range(n_qubits)))\n",
    "\n",
    "\n",
    "\n",
    "class QuantumGenerator(nn.Module):\n",
    "\n",
    "    def __init__(self, n_qubits, ancillary_qubits, gen_n_layers, n_generators, device, q_delta=1):\n",
    "        super(QuantumGenerator, self).__init__()\n",
    "\n",
    "        self.n_qubits = n_qubits\n",
    "        self.ancillary_qubits = ancillary_qubits\n",
    "        self.gen_n_layers = gen_n_layers\n",
    "        #self.n_gate_per_layer = n_gate_per_layer\n",
    "        self.n_generators = n_generators\n",
    "        self.device = device\n",
    "        self.vqc_params = nn.ParameterList([nn.Parameter(q_delta * torch.rand(self.gen_n_layers * self.n_qubits), \n",
    "                                          requires_grad=True)for _ in range(self.n_generators)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        patch_size = 2 ** (self.n_qubits - self.ancillary_qubits)\n",
    "\n",
    "        images = torch.Tensor(x.size(0), 0).to(self.device)\n",
    "\n",
    "        # Iterate over all sub-generators\n",
    "        for params in self.vqc_params:\n",
    "            \n",
    "            patches = torch.Tensor(0, patch_size).to(self.device)\n",
    "            for elem in x:\n",
    "                \n",
    "                probs = quantum_generator_circuit(elem, params, self.gen_n_layers, self.n_qubits)\n",
    "                partial_measure = probs[: (2 ** (n_qubits - self.ancillary_qubits))]\n",
    "                partial_measure /= torch.sum(probs)\n",
    "            \n",
    "                out = partial_measure / torch.max(partial_measure)\n",
    "                out = out.float().unsqueeze(0)\n",
    "                patches = torch.cat((patches, out))\n",
    "\n",
    "            # Building the image\n",
    "            images = torch.cat((images, patches), 1)\n",
    "            #print(images.shape)\n",
    "\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, image_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        self.image_size = image_size\n",
    "        self.linear1 = nn.Linear(self.image_size * self.image_size, 64)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        #self.linear2 = nn.Linear(64, 16)\n",
    "        #self.relu2 = nn.LeakyReLU()\n",
    "        self.linear3 = nn.Linear(64, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu1(x)\n",
    "        #x = self.linear2(x)\n",
    "        #x = self.relu2(x)\n",
    "        x = self.linear3(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Discriminator(nn.Module):\n",
    "#     \"\"\"Fully connected classical discriminator\"\"\"\n",
    "\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self.model = nn.Sequential(\n",
    "#             # Inputs to first hidden layer (num_input_features -> 64)\n",
    "#             nn.Linear(8*8, 64),\n",
    "#             nn.ReLU(),\n",
    "#             # First hidden layer (64 -> 16)\n",
    "#             nn.Linear(64, 16),\n",
    "#             nn.ReLU(),\n",
    "#             # Second hidden layer (16 -> output)\n",
    "#             nn.Linear(16, 1),\n",
    "#             nn.Sigmoid(),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN():\n",
    "    def __init__(self, network_type, dataloader, gen_net, disc_net, noise_dim, image_size, batch_size, loss, lr_gen, lr_disc, device, save_path):\n",
    "\n",
    "        # for '0' and '1' features ---> opt = torch.Adam, random = torch.randn, epochs = 1000, lr_disc = lr_gen = 0.0001\n",
    "        self.network_type = network_type\n",
    "        self.dataloader = dataloader\n",
    "        self.gen_net = gen_net\n",
    "        self.disc_net = disc_net\n",
    "        self.noise_dim = noise_dim \n",
    "        self.image_size = image_size\n",
    "        self.batch_size = batch_size\n",
    "        self.lr_gen = lr_gen\n",
    "        self.lr_disc = lr_disc\n",
    "        self.loss = loss\n",
    "        self.device = device\n",
    "        self.save_path = save_path\n",
    "\n",
    "        self.gen_opt = optim.SGD(self.gen_net.parameters(), lr=self.lr_gen)\n",
    "        self.disc_opt = optim.SGD(self.disc_net.parameters(), lr=self.lr_disc)        \n",
    "\n",
    "        self.real_labels = torch.full((self.batch_size,), 1.0, dtype=torch.float, device=self.device)\n",
    "        self.fake_labels = torch.full((self.batch_size,), 0.0, dtype=torch.float, device=self.device)\n",
    "\n",
    "        self.loss_g = []\n",
    "        self.loss_d = []\n",
    "\n",
    "    \n",
    "    def train_step(self, data):\n",
    "\n",
    "        # Data for training the discriminator\n",
    "        data = data.reshape(-1, self.image_size * self.image_size)\n",
    "        real_data = data.to(self.device)\n",
    "\n",
    "        # Generating noise\n",
    "        noise = torch.rand(self.batch_size, self.noise_dim, device=self.device) * np.pi / 2\n",
    "        fake_data = self.gen_net(noise)\n",
    "\n",
    "        #---------------- Discriminator training ----------------# \n",
    "        self.disc_opt.zero_grad()\n",
    "        disc_out_real = self.disc_net(real_data).view(-1)\n",
    "        disc_out_fake = self.disc_net(fake_data.detach()).view(-1)\n",
    "\n",
    "        disc_error_real = self.loss(disc_out_real, self.real_labels)\n",
    "        disc_error_fake = self.loss(disc_out_fake, self.fake_labels)\n",
    "        \n",
    "        disc_error_real.backward()\n",
    "        disc_error_fake.backward()\n",
    "\n",
    "        disc_error = disc_error_real + disc_error_fake\n",
    "        self.disc_opt.step()\n",
    "\n",
    "        #---------------- Generator training ----------------#\n",
    "        self.gen_opt.zero_grad()\n",
    "        # Generating fake images\n",
    "        noise = torch.rand(self.batch_size, self.noise_dim)\n",
    "        fake_data = self.gen_net(noise)\n",
    "        disc_out_fake = self.disc_net(fake_data).view(-1)\n",
    "        gen_error = self.loss(disc_out_fake, self.real_labels)\n",
    "        gen_error.backward()\n",
    "        self.gen_opt.step()        \n",
    "\n",
    "        self.loss_g.append(gen_error.item())\n",
    "        self.loss_d.append(disc_error.item())\n",
    "\n",
    "        return gen_error, disc_error\n",
    "\n",
    "\n",
    "    def learn(self, epochs):\n",
    "\n",
    "        # Setting fixed noise \n",
    "        fixed_noise = torch.rand(8, self.noise_dim, device=self.device) * np.pi / 2\n",
    "\n",
    "        self.results = []\n",
    "        \n",
    "        self.ep_d_loss = []\n",
    "        self.ep_g_loss = []    \n",
    "                      \n",
    "        \n",
    "        with tqdm(range(epochs)) as tepochs:#total=len(self.dataloader), ncols=140, desc=f'epoch {epoch}') as bar:\n",
    "\n",
    "            for epoch in tepochs:\n",
    "\n",
    "                self.loss_g = []\n",
    "                self.loss_d = []     \n",
    "        \n",
    "                for data, _ in self.dataloader:\n",
    "\n",
    "                    lg, ld = self.train_step(data)\n",
    "\n",
    "                    #counter += 1\n",
    "\n",
    "                    # Show loss values         \n",
    "                    #if epoch % 10 == 0:\n",
    "                     \n",
    "\n",
    "                    # if epoch == epochs:\n",
    "                    #     break\n",
    "\n",
    "                    self.loss_g.append(lg.item())\n",
    "                    self.loss_d.append(ld.item())                    \n",
    "                    \n",
    "                    #bar.update(1)\n",
    "                    #bar.set_postfix({'Generator loss' : lg.item(), 'Discriminator loss': ld.item()})\n",
    "                \n",
    "                test_images = self.gen_net(fixed_noise).view(8,1,self.image_size,self.image_size).cpu().detach()\n",
    "                if self.network_type == 'Classical_linear':\n",
    "                    torch.save(self.gen_net, self.save_path + f'lin_gen_epoch_{epoch}')\n",
    "                elif self.network_type == 'Quantum_linear':\n",
    "                    torch.save(self.gen_net, self.save_path + f'lin_q_gen_epoch_{epoch}')\n",
    "                else:\n",
    "                    print('Typology not admitted.')\n",
    "                \n",
    "        \n",
    "                self.results.append(test_images)\n",
    "                self.ep_g_loss.append(np.mean(self.loss_g))\n",
    "                self.ep_d_loss.append(np.mean(self.loss_d))\n",
    "\n",
    "                torch.save(self.results, self.save_path + 'synthetic.pt')  \n",
    "                torch.save(self.ep_g_loss, self.save_path + 'gen_loss.pt') \n",
    "                torch.save(self.ep_d_loss, self.save_path + 'disc_loss.pt')  \n",
    "\n",
    "                \n",
    "                tepochs.set_postfix({'Generator loss' : np.mean(self.loss_g), 'Discriminator loss': np.mean(self.loss_d)})\n",
    "\n",
    "            # if epoch == epochs:\n",
    "            #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-26 10:52:20.542691: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-01-26 10:52:20.542745: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-01-26 10:52:20.542768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vt-bozzololu): /proc/driver/nvidia/version does not exist\n",
      "2023-01-26 10:52:20.542977: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "#save_path = 'torch_results/GAN/GAN_linear/' + current_time + '/'\n",
    "save_path = 'torch_results/QGAN/QGAN_linear/' + current_time + '/'\n",
    "summary_writer = tf.summary.create_file_writer(save_path)\n",
    "\n",
    "noise_dim = 5\n",
    "image_size = 8\n",
    "batch_size = 1\n",
    "loss = nn.BCELoss()\n",
    "lr_gen = 0.03#0.03#0.0001\n",
    "lr_disc = 0.01#0.0001\n",
    "epochs = 2\n",
    "n_qubits = 5 \n",
    "ancillary_qubits = 1  \n",
    "gen_n_layers = 6  \n",
    "n_generators = 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(image_size).to(device)\n",
    "qgenerator = QuantumGenerator(n_qubits, ancillary_qubits, gen_n_layers, n_generators, device).to(device)\n",
    "generator = Generator(noise_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [06:43<00:00, 201.55s/it, Generator loss=0.843, Discriminator loss=0.679]\n"
     ]
    }
   ],
   "source": [
    "gan = GAN(network_type = 'Quantum_linear', dataloader = dataloader, gen_net = qgenerator, disc_net = discriminator, noise_dim = noise_dim, image_size = image_size, batch_size = batch_size, loss = loss,\n",
    "          lr_gen = lr_gen, lr_disc = lr_disc, device = device, save_path = save_path)\n",
    "\n",
    "gan.learn(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(10, 5))\n",
    "# outer = gridspec.GridSpec(len(gan.results), 2, wspace=0.1)\n",
    "\n",
    "# for i, images in enumerate(gan.results):\n",
    "#     inner = gridspec.GridSpecFromSubplotSpec(1, images.size(0), subplot_spec=outer[i])\n",
    "    \n",
    "#     images = torch.squeeze(images, dim=1)\n",
    "#     for j, im in enumerate(images):\n",
    "\n",
    "#         ax = plt.Subplot(fig, inner[j])\n",
    "#         ax.imshow(im.numpy(), cmap=\"gray\")\n",
    "#         ax.set_xticks([])\n",
    "#         ax.set_yticks([])\n",
    "#         if j==0:\n",
    "#             ax.set_title(f'Epoch {i}', loc='left')\n",
    "#         fig.add_subplot(ax)\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "f, axarr = plt.subplots(8, 8) \n",
    "for i, ax in enumerate(axarr.ravel()):\n",
    "    ax.imshow(qgenerator(torch.rand(1,noise_dim)).detach().numpy().reshape(8,8), cmap = 'gray')\n",
    "    ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "f.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, generator(torch.rand(1,noise_dim)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = torch.load('torch_results/GAN/GAN_linear/20230103-180533/lin_gen_epoch_2')   # '0' features\n",
    "#model = torch.load('torch_results/GAN/GAN_linear/20230110-142423/lin_gen_epoch_2')   # '1' features\n",
    "\n",
    "#model = torch.load('torch_results/GAN/GAN_conv/20221229-091505/conv_gen_epoch_2000')\n",
    "\n",
    "#model = torch.load('torch_results/GAN/GAN_linear/20221219-092917/gen_epoch_1500') # '0','1' features\n",
    "#model = torch.load('torch_results/GAN/GAN_linear/20221219-100153/gen_epoch_2000')  # '0','1','2' features\n",
    "#model.eval()\n",
    "\n",
    "# GAN_imgs = []\n",
    "\n",
    "# fixed_noise = torch.rand(1, 5) \n",
    "# for i in range(len(real_data)):      \n",
    "     \n",
    "#     image = model(fixed_noise).view(1,8,8).cpu().detach()\n",
    "#     GAN_imgs.append(image)\n",
    "\n",
    "# show_images(GAN_imgs, 8), GAN_imgs[0].shape\n",
    "\n",
    "# noise_dim = 5\n",
    "\n",
    "# plt.figure()\n",
    "# f, axarr = plt.subplots(8, 8) \n",
    "# for i, ax in enumerate(axarr.ravel()):\n",
    "#     ax.imshow(model(torch.rand(1,noise_dim)).detach().numpy().reshape(8,8), cmap = 'gray')\n",
    "#     ax.tick_params(left=False, bottom=False, labelleft=False, labelbottom=False)\n",
    "# f.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model, model(torch.rand(1,noise_dim)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(epochs)\n",
    "plt.plot(x, gan.ep_d_loss, label = \"Discriminator loss\")\n",
    "plt.plot(x, gan.ep_g_loss, label = \"Generator loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "41b44beeb6ae1f78ee853589a4fc9a204ef8b2c5ec7d95e779faecfadf9e001f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
